{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 Assignment - Capstone Check-in\n",
    "\n",
    "## Author - Elizabeth Lunsford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capstone Project Instructions\n",
    "Select a problem and data sets of particular interest and apply the analytics process to find and report on a solution.\n",
    "\n",
    "Students will construct a simple dashboard to allow a non-technical user to explore their solution. The data should be read from a suitable persistent data storage, such as an Internet URL or a SQL data base.\n",
    "\n",
    "The process followed by the students and the grading criteria include:\n",
    "<ol style=\"list-style-type: lower-alpha;\">\n",
    "<li>Understand the business problem <span class=\"label\" style=\"border-radius: 3px; background-color: darkcyan; color: white;\">Milestone 1</span></li>\n",
    "<li>Evaluate and explore the available data <span class=\"label\" style=\"border-radius: 3px; background-color: darkcyan; color: white;\">Milestone 1</span></li>\n",
    "<li>Proper data preparation <span class=\"label\" style=\"border-radius: 3px; background-color: darkcyan; color: white;\">Milestone 1</span> <span class=\"label\" style=\"border-radius: 3px; background-color: royalblue; color: white;\">Milestone 2</span></li>\n",
    "<li>Exploration of data and understand relationships <span class=\"label\" style=\"border-radius: 3px; background-color: darkcyan; color: white;\">Milestone 1</span> <span class=\"label\" style=\"border-radius: 3px; background-color: royalblue; color: white;\">Milestone 2</span></li>\n",
    "<li>Perform basic analytics and machine learning, within the scope of the course, on the data.  <span class=\"label\" style=\"border-radius: 3px; background-color: royalblue; color: white;\">Milestone 2</span> <span class=\"label\" style=\"border-radius: 3px; background-color: slateblue; color: white;\">Milestone 3</span> <BR/>For example, classification to predict which employees are most likely to leave the company.</li>\n",
    "<li>Create a written and/or oral report on the results suitable for a non-technical audience. <span class=\"label\" style=\"border-radius: 3px; background-color: slateblue; color: white;\">Milestone 3</span></li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "<img src=\"https://library.startlearninglabs.uw.edu/DATASCI420/img/Milestone2Sample.PNG\" style=\"float: right; width: 400px;\">\n",
    "For this check-in, you are to:\n",
    "\n",
    "1). Explicitly state the problem, list sources, and define the methodology: classification, regression, other\n",
    "\n",
    "2). List data processing steps (psuedo code) including steps from data source collection & preparation, feature engineering & selection, modeling, performance evaluation.\n",
    "\n",
    "3). Read in the previously generated data file of cleaned up data\n",
    "\n",
    "4). Perform feature engineering and selection\n",
    "\n",
    "5). Conduct some preliminary modeling \n",
    "\n",
    "6). Identify potential machine learning model(s) to improve performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "\n",
    "### Project Goal\n",
    "The goal of this project is to predict if a state votes for a Republican or Democratic candidiate.\n",
    "\n",
    "### Problem Statement\n",
    "How much does a state's social demographics influence how a state votes?  \n",
    " \n",
    "### Problem Definition\n",
    "Understanding how the United States of America is governed is a complex problem. Simply described as a democracy where people vote for elected officials is an overgeneralization for the constitutional federal republic which is governed by three branches; executive, legislative and judicial. The judicial branch ensures that implemented laws are in accordance with the constitution that can be either places by the executive or legislative branches.\n",
    "\n",
    "Each state has its own constitution and form of government that is also structured with executive, legislative and judicial branch. A republic is a form of government in which the people elect representatives. In the United States, people elect officials into the legislative branches based on popular vote. The Federal Executive branch which included the President and Vice President of the United States is elected by an electoral college. The electoral college mainly consists of two political parties; the Democratic and Republican Party\n",
    "\n",
    "The republic is not required to vote or align themselves to a political party. Therefore voter turnout is a dynamic variable and a state’s political majority can change at every election. To help understand how the United States is govern, we will study if social demographics have an influence on how people vote. Using Machine Learning Algorithms, we will create model to predict each state’s range of voter turnout and which party will be elected in federal elections.\n",
    "\n",
    "### List of Raw Data Sources\n",
    "* United States Presidential Election Results Data Set: \"https://uselectionatlas.org/RESULTS/\"\n",
    "* United States Legislative Branch Party Composition: https://www.kaggle.com/kiwiphrases/partystrengthbystate#states_party_strength_cleaned.csv\n",
    "* Employment / unemployment data: https://data.bls.gov/PDQWeb/la\n",
    "*  Poverty and income estimates data: https://www.census.gov/data-tools/demo/saipe/saipe.html?s_appName=saipe&menu=grid_proxy&s_USStOnly=y&map_yearSelector=2016&map_geoSelector=aa_c&s_measures=aa_snc\n",
    "* Education Spending per student, 2016 dollars, by state, 2007-2016, (Pre-K through 12): http://www.governing.com/gov-data/education-data/state-education-spending-per-pupil-data.html\n",
    "* National Public Education Financial Survey Data (Pre-K through 12):https://nces.ed.gov/ccd/stfis.asp\n",
    "\n",
    "### List of Data Sources from Milestone 1 to use for Milestone 2\n",
    "* political_data.csv - Election data\n",
    "* final_dataset.csv - Demographic data\n",
    "* state_edu_spending.csv - Educational Finance data\n",
    "\n",
    "### Methodology\n",
    "* Classification of if a state votes Republican or Democrat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Steps\n",
    "###  List data processing steps (psuedo code) including steps from data source collection & preparation, feature engineering & selection, modeling, performance evaluation.\n",
    "1. Data Source Collection and Preparartion\n",
    " 1. Load three data files into dataframes\n",
    "    1. Process each dataframe to have the same names for state and year\n",
    "    1. Merge dataframes based on state and year\n",
    " 2. Analysis and Process combined dataframe\n",
    "    2. Drop duplicate entries, create key fields, and create flag field noting combine participation\n",
    " 3. Clean the target value \n",
    "\n",
    "### Read in the previously generated data file of cleaned up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Read data files into dataframes\n",
    "df_p = pd.read_csv(\"political_data.csv\", header=0)\n",
    "df_d = pd.read_csv(\"final_dataset.csv\", header=0)\n",
    "df_e = pd.read_csv(\"state_edu_spending.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View political data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most political data attributes are leakage to the target value since they are the results of\n",
    "#  other political seats election results, therefore only use the following values\n",
    "df_p = df_p[['year', 'state', 'population', 'total_vap', 'perc_vap', 'perc_reg', 'd_placed', 'r_placed']]\n",
    "\n",
    "# Keep first place as 1 but convert second place as 0, there 1 would be win and 0 would be lost\n",
    "df_p['d_placed'] = df_p.d_placed.replace(2,0)\n",
    "df_p['r_placed'] = df_p.r_placed.replace(2,0)\n",
    "\n",
    "# 3rd values means a third party came in first or second place\n",
    "# If a value is 3, that means the did not come in first or win, so convert 3 to 0 which means lost\n",
    "df_p['d_placed'] = df_p.d_placed.replace(3,0)\n",
    "df_p['r_placed'] = df_p.r_placed.replace(3,0)\n",
    "\n",
    "df_p['d_won'] = df_p['d_placed']\n",
    "df_p = df_p.drop(['d_placed', 'r_placed'], axis =1)\n",
    "\n",
    "# View political data\n",
    "#pandas_profiling.ProfileReport(df_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View educational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(df_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction_expensive is highly coordinated enough with total_edu_expense to be dropped\n",
    "df_e = df_e.drop(['instruction_expense'], axis =1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(df_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df_d[['All Ages in Poverty Percent', 'Median Household Income in Dollars', 'State', 'Year', 'labor force', 'unemployment rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to shorter names\n",
    "df_d = df_d.rename(columns={\n",
    "'All Ages in Poverty Percent': 'poverty',\n",
    "'Median Household Income in Dollars': 'income',\n",
    "'labor force': 'labor',\n",
    "'unemployment rate': 'unemployment' })\n",
    "\n",
    "# Make all column names lowercase\n",
    "df_d = df_d.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Impute missing values with mean values\n",
    "# Each state value will have it's own mean\n",
    "# Loop through each state and impute variables with missing values\n",
    "states = df_d.state.unique()\n",
    "attributes = [\"income\", \"poverty\"]\n",
    "for state in states:\n",
    "    for attribute in attributes:\n",
    "        #df_d[attribute] = df_d[attribute].replace(\"-\", 0).astype(float)\n",
    "        mean_value = df_d.loc[(df_d[\"state\"] == state) & (df_d[attribute] > 0), attribute].values.mean()\n",
    "        df_d.loc[((df_d[\"state\"] == state) & (df_d[attribute] == 0)), [attribute]] = mean_value \n",
    "        df_d[attribute] = df_d[attribute].fillna(mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean that state values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all state values lowercase\n",
    "df_p['state'] = df_p.state.str.lower()\n",
    "df_d['state'] = df_d.state.str.lower()\n",
    "df_e['state'] = df_e.state.str.lower()\n",
    "\n",
    "# Check state data in political dataset\n",
    "# sorted(df_p.state.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['district of columbia' 'puerto rico']\n",
      "['american samoa' 'american somoa' 'district of columbia' 'guam'\n",
      " 'northern mariana islands' 'northern marianas' 'puerto rico'\n",
      " 'virgin islands']\n"
     ]
    }
   ],
   "source": [
    "# Compare political dataset to demographic dataset\n",
    "print(np.setdiff1d(df_d.state.unique(), df_p.state.unique()))\n",
    "\n",
    "# Compare political dataset to educational dataset\n",
    "print(np.setdiff1d(df_e.state.unique(), df_p.state.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make d.c. data values that same in all three datasets\n",
    "df_p['state'] = df_p.state.replace('d.c.', 'district of columbia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the year data up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  political data 2016 1980 \n",
      " educational data 2016 2000 \n",
      " demographic data 2017 1976\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "'  political data', df_p.year.max(), df_p.year.min(), '\\n',\n",
    "'educational data', df_e.year.max(), df_e.year.min(), '\\n',\n",
    "'demographic data', df_d.year.max(), df_d.year.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      year           state  population     total_vap   perc_vap  perc_reg  \\\n",
       "0    2016         arizona   6931071.0  2.650448e+06  47.136364    63.700   \n",
       "1    2016        arkansas   2988248.0  1.716395e+06  50.254545    64.200   \n",
       "2    2016      california  39250017.0  2.020329e+07  50.263636    73.300   \n",
       "3    2016        colorado   5540545.0  2.483406e+06  58.781818    72.400   \n",
       "4    2016     connecticut   3576452.0  2.381272e+06  61.490909    69.800   \n",
       "5    2016        delaware    952065.0  4.923307e+05  57.572727    65.700   \n",
       "6    2016         florida  20612439.0  9.349346e+06  50.636364    73.975   \n",
       "7    2016         georgia  10310371.0  4.732607e+06  44.127273    76.100   \n",
       "8    2016          hawaii   1428557.0  7.747332e+05  44.936364    57.200   \n",
       "9    2016           idaho   1683140.0  7.363475e+05  61.781818    73.700   \n",
       "10   2016        illinois  12801539.0  8.441006e+06  57.554545    69.700   \n",
       "11   2016         indiana   6633053.0  4.047533e+06  56.618182    57.100   \n",
       "12   2016            iowa   3134693.0  2.073181e+06  63.609091    72.100   \n",
       "13   2016          kansas   2907289.0  1.785927e+06  58.545455    65.700   \n",
       "14   2016        kentucky   4436974.0  2.710630e+06  51.172727    58.200   \n",
       "15   2016        kentucky   4436974.0  2.710630e+06  51.172727    58.200   \n",
       "16   2016       louisiana   4681666.0  2.917320e+06  54.363636    67.100   \n",
       "17   2016           maine   1331479.0  8.639041e+05  66.300000    70.300   \n",
       "18   2016        maryland   6016447.0  3.415824e+06  52.309091    75.050   \n",
       "19   2016   massachusetts   6811779.0  4.438830e+06  59.790909    73.300   \n",
       "20   2016        michigan   9928300.0  6.669804e+06  60.054545    64.200   \n",
       "21   2016       minnesota   5519952.0  3.145540e+06  70.027273    81.300   \n",
       "22   2016     mississippi   2988726.0  1.801205e+06  51.027273    58.100   \n",
       "23   2016        missouri   6093000.0  3.756101e+06  59.254545    67.000   \n",
       "24   2016         montana   1042520.0  5.887501e+05  65.118182    72.300   \n",
       "25   2016        nebraska   1907116.0  1.154604e+06  58.018182    69.700   \n",
       "26   2016          nevada   2940058.0  9.545933e+05  45.863636    67.000   \n",
       "27   2016   new hampshire   1334795.0  7.654441e+05  61.472727    73.200   \n",
       "28   2016      new jersey   8944469.0  5.722352e+06  56.372727    67.300   \n",
       "29   2016      new mexico   2081015.0  1.043589e+06  52.272727    61.900   \n",
       "..    ...             ...         ...           ...        ...       ...   \n",
       "251  2000       minnesota   4919479.0  3.632940e+06  67.100000    74.700   \n",
       "252  2000     mississippi   2844658.0  2.070254e+06  48.100000    57.200   \n",
       "253  2000        missouri   5595211.0  4.169109e+06  56.600000    61.100   \n",
       "254  2000        missouri   5595211.0  4.169109e+06  56.600000    61.100   \n",
       "255  2000         montana    902195.0  6.722510e+05  61.100000    58.900   \n",
       "256  2000        nebraska   1711263.0  1.261648e+06  55.200000    64.200   \n",
       "257  2000          nevada   1998257.0  1.488526e+06  40.900000    69.700   \n",
       "258  2000   new hampshire   1235786.0  9.268850e+05  61.400000    66.600   \n",
       "259  2000      new jersey   8414350.0  6.332876e+06  50.300000    67.700   \n",
       "260  2000      new mexico   1819046.0  1.311478e+06  45.600000    61.500   \n",
       "261  2000        new york  18976457.0  1.430227e+07  47.800000    60.700   \n",
       "262  2000  north carolina   8049313.0  6.087996e+06  47.800000    56.800   \n",
       "263  2000    north dakota    642200.0  4.813010e+05  59.900000    75.300   \n",
       "264  2000            ohio  11353140.0  8.467999e+06  55.600000    62.400   \n",
       "265  2000        oklahoma   3450654.0  2.560390e+06  48.200000    55.300   \n",
       "266  2000          oregon   3421399.0  2.577129e+06  59.500000    78.500   \n",
       "267  2000    pennsylvania  12281054.0  9.362066e+06  52.500000    63.100   \n",
       "268  2000    rhode island   1048319.0  8.008100e+05  51.100000    60.900   \n",
       "269  2000  south carolina   4012012.0  3.002919e+06  46.100000    61.100   \n",
       "270  2000    south dakota    754844.0  5.521180e+05  57.300000    67.100   \n",
       "271  2000       tennessee   5689283.0  4.292047e+06  48.400000    65.300   \n",
       "272  2000           texas  20851820.0  1.497784e+07  42.800000    62.400   \n",
       "273  2000           texas  20851820.0  1.497784e+07  42.800000    62.400   \n",
       "274  2000            utah   2233169.0  1.516338e+06  50.800000    68.600   \n",
       "275  2000         vermont    608827.0  4.612480e+05  63.800000    68.900   \n",
       "276  2000        virginia   7078515.0  5.342691e+06  51.300000    72.600   \n",
       "277  2000      washington   5894121.0  4.384341e+06  56.800000    74.600   \n",
       "278  2000   west virginia   1808344.0  1.406569e+06  46.100000    60.800   \n",
       "279  2000       wisconsin   5363675.0  3.996289e+06  65.000000    82.200   \n",
       "280  2000         wyoming    493782.0  3.656850e+05  59.700000    99.200   \n",
       "\n",
       "     d_won  poverty   income     labor  unemployment  total_revenue  \\\n",
       "0        0     16.4  53481.0   3225703           5.4   9.727226e+09   \n",
       "1        0     17.2  44406.0   1342561           3.9   5.524230e+09   \n",
       "2        1     14.4  67715.0  19093658           5.5   6.879300e+10   \n",
       "3        1     11.0  65718.0   2893268           3.3   9.093336e+09   \n",
       "4        1      9.9  73380.0   1904556           5.1   1.074060e+10   \n",
       "5        1     11.8  62112.0    473881           4.5   1.956343e+09   \n",
       "6        0     14.8  50857.0   9846000           4.8   2.507649e+10   \n",
       "7        0     16.1  53468.0   4926945           5.4   1.841945e+10   \n",
       "8        1      9.5  74659.0    684167           2.9   2.650013e+09   \n",
       "9        0     13.8  51647.0    812856           3.8   2.155786e+09   \n",
       "10       1     13.0  60977.0   6549991           5.8   3.048814e+10   \n",
       "11       0     14.0  52289.0   3327139           4.4   1.248256e+10   \n",
       "12       0     11.7  56354.0   1696113           3.6   6.312853e+09   \n",
       "13       0     12.2  54828.0   1485336           4.0   6.059433e+09   \n",
       "14       0     18.2  46610.0   2012279           5.1   7.408128e+09   \n",
       "15       0     18.2  46610.0   2012279           5.1   7.408128e+09   \n",
       "16       0     20.1  45374.0   2125934           6.0   8.793692e+09   \n",
       "17       1     12.3  52926.0    692154           3.8   2.672119e+09   \n",
       "18       1      9.7  78787.0   3178646           4.4   1.436799e+10   \n",
       "19       1     10.5  75207.0   3611418           3.9   1.655322e+10   \n",
       "20       0     14.9  52436.0   4840281           5.0   1.960171e+10   \n",
       "21       1      9.9  65583.0   3036278           3.9   1.148811e+10   \n",
       "22       0     21.0  41793.0   1278960           5.8   4.642588e+09   \n",
       "23       0     14.0  51713.0   3079559           4.6   1.068528e+10   \n",
       "24       0     13.4  50265.0    521628           4.1   1.696318e+09   \n",
       "25       0     11.3  56979.0   1008715           3.1   3.950130e+09   \n",
       "26       1     14.1  55201.0   1430344           5.7   4.325365e+09   \n",
       "27       1      7.6  70986.0    746452           2.9   2.994675e+09   \n",
       "28       1     10.4  76212.0   4530784           5.0   2.779650e+10   \n",
       "29       1     19.1  46844.0    928732           6.7   3.775343e+09   \n",
       "..     ...      ...      ...       ...           ...            ...   \n",
       "251      1      6.9  49170.0   2812947           3.2   1.001898e+10   \n",
       "252      0     17.6  32542.0   1319266           5.4   3.872596e+09   \n",
       "253      0     10.6  40411.0   2959946           3.6   9.289893e+09   \n",
       "254      0     10.6  40411.0   2959946           3.6   9.289893e+09   \n",
       "255      0     13.3  33281.0    467293           5.0   1.535396e+09   \n",
       "256      0      8.9  40429.0    944973           2.8   3.089506e+09   \n",
       "257      0      9.4  44698.0   1067022           4.2   3.152708e+09   \n",
       "258      0      5.6  49830.0    687908           2.7   2.173796e+09   \n",
       "259      1      7.8  52990.0   4282069           3.7   2.075495e+10   \n",
       "260      1     17.3  34487.0    845755           4.9   3.123125e+09   \n",
       "261      1     13.2  41763.0   9133869           4.5   4.516238e+10   \n",
       "262      0     11.7  38889.0   4138190           3.7   1.226136e+10   \n",
       "263      0     10.4  35636.0    342568           3.0   1.045238e+09   \n",
       "264      0      9.8  42054.0   5787343           4.0   2.122861e+10   \n",
       "265      0     13.8  33417.0   1660528           3.0   5.164462e+09   \n",
       "266      1     10.6  41662.0   1818559           5.1   6.040533e+09   \n",
       "267      1      9.5  41419.0   6106892           4.1   2.261369e+10   \n",
       "268      1     10.2  42305.0    543561           4.1   2.018464e+09   \n",
       "269      0     12.8  37283.0   1993562           3.8   6.853838e+09   \n",
       "270      0     11.4  36146.0    408658           2.5   1.205667e+09   \n",
       "271      0     12.6  35760.0   2843069           3.9   7.496424e+09   \n",
       "272      0     14.6  39090.0  10374053           4.3   3.994126e+10   \n",
       "273      0     14.6  39090.0  10374053           4.3   3.994126e+10   \n",
       "274      0      8.8  45934.0   1142044           3.3   3.594658e+09   \n",
       "275      1      8.8  40537.0    331404           2.8   1.346559e+09   \n",
       "276      0      8.9  46789.0   3605811           2.3   1.219514e+10   \n",
       "277      1      9.6  44846.0   3059339           5.2   1.055608e+10   \n",
       "278      0     15.5  30187.0    809063           5.5   3.198343e+09   \n",
       "279      1      8.1  44503.0   2973221           3.5   1.085131e+10   \n",
       "280      0     10.4  38934.0    266808           3.9   1.096314e+09   \n",
       "\n",
       "     property_expense  total_edu_expense  per_pupil_expense  \n",
       "0        3.731450e+08       9.358784e+09        7613.006435  \n",
       "1        2.255353e+08       5.501220e+09        9845.568548  \n",
       "2        7.354426e+08       6.848896e+10       11495.330166  \n",
       "3        2.500031e+08       8.482343e+09        9574.742414  \n",
       "4        1.995604e+08       1.060752e+10       18957.841335  \n",
       "5        2.547481e+07       2.041926e+09       14713.367705  \n",
       "6        5.459267e+08       2.623991e+10        8919.956657  \n",
       "7        2.447229e+08       1.799946e+10        9768.705072  \n",
       "8        1.593832e+07       2.435585e+09       13748.278799  \n",
       "9        6.106680e+07       2.085185e+09        7157.395515  \n",
       "10       7.519048e+08       2.857002e+10       14180.030994  \n",
       "11       6.160315e+08       1.156758e+10        9856.308393  \n",
       "12       2.023138e+08       6.178332e+09       11150.206490  \n",
       "13       2.553123e+08       5.810340e+09        9959.640396  \n",
       "14       2.205084e+08       7.541811e+09        9862.914457  \n",
       "15       2.205084e+08       7.541811e+09        9862.914457  \n",
       "16       1.438974e+08       8.693573e+09       11038.296236  \n",
       "17       3.289257e+07       2.592320e+09       13278.159207  \n",
       "18       1.378468e+08       1.362814e+10       14205.765267  \n",
       "19       6.936762e+08       1.602228e+10       15592.739208  \n",
       "20       4.379949e+08       1.899743e+10       11667.993798  \n",
       "21       3.405622e+08       1.102595e+10       12381.964281  \n",
       "22       1.626373e+08       4.466059e+09        8701.854004  \n",
       "23       2.643504e+08       1.026252e+10       10312.778587  \n",
       "24       3.143141e+07       1.711713e+09       11348.313137  \n",
       "25       1.350555e+08       3.878472e+09       12298.901573  \n",
       "26       5.530308e+07       4.101856e+09        8960.113038  \n",
       "27       6.891463e+07       2.938084e+09       15340.217718  \n",
       "28       1.822444e+08       2.660314e+10       18402.354609  \n",
       "29       1.628980e+07       3.721089e+09        9692.697766  \n",
       "..                ...                ...                ...  \n",
       "251      4.273052e+08       1.022349e+10        9903.054020  \n",
       "252      1.701043e+08       4.005355e+09        6788.527154  \n",
       "253      3.780614e+08       9.124951e+09        8775.690978  \n",
       "254      3.780614e+08       9.124951e+09        8775.690978  \n",
       "255      3.567176e+07       1.480660e+09        8991.260952  \n",
       "256      1.749200e+08       3.007904e+09        9418.223644  \n",
       "257      1.456445e+08       3.228924e+09        8074.068434  \n",
       "258      5.810777e+07       2.163534e+09        9519.524781  \n",
       "259      4.529221e+08       2.052286e+10       14650.624626  \n",
       "260      1.680483e+08       3.041984e+09        7639.157928  \n",
       "261      8.260245e+08       4.389771e+10       14726.367018  \n",
       "262      4.848392e+08       1.275307e+10        8626.801117  \n",
       "263      4.814862e+07       1.010114e+09        7657.124940  \n",
       "264      1.921106e+09       2.057972e+10       10118.086436  \n",
       "265      1.122892e+08       5.068402e+09        7347.043334  \n",
       "266      1.714457e+08       6.000015e+09       10740.833886  \n",
       "267      3.797331e+08       2.273942e+10       11119.776279  \n",
       "268      3.238644e+07       1.996062e+09       12971.688954  \n",
       "269      3.219163e+08       6.773768e+09        8470.956475  \n",
       "270      8.589404e+07       1.232669e+09        7888.550882  \n",
       "271      2.959302e+08       7.947956e+09        7625.506871  \n",
       "272      1.521583e+09       4.178452e+10        8878.030719  \n",
       "273      1.521583e+09       4.178452e+10        8878.030719  \n",
       "274      1.714192e+08       3.532274e+09        6232.377751  \n",
       "275      2.950970e+07       1.274886e+09       11755.560910  \n",
       "276      6.851128e+08       1.228959e+10        8702.440308  \n",
       "277      3.629950e+08       1.042454e+10        9059.055081  \n",
       "278      1.468121e+08       3.160511e+09       10054.767013  \n",
       "279      3.924894e+08       1.091577e+10       11012.503300  \n",
       "280      4.539488e+07       1.052259e+09       10543.188328  \n",
       "\n",
       "[281 rows x 15 columns]>"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd = pd.merge(df_p,df_d, on=['state','year'])\n",
    "df = pd.merge(df_pd, df_e, on =['state', 'year'])\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode state\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.state)\n",
    "df['state'] = le.transform(df.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>total_vap</th>\n",
       "      <th>perc_vap</th>\n",
       "      <th>perc_reg</th>\n",
       "      <th>d_won</th>\n",
       "      <th>poverty</th>\n",
       "      <th>income</th>\n",
       "      <th>labor</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>property_expense</th>\n",
       "      <th>total_edu_expense</th>\n",
       "      <th>per_pupil_expense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, state, population, total_vap, perc_vap, perc_reg, d_won, poverty, income, labor, unemployment, total_revenue, property_expense, total_edu_expense, per_pupil_expense]\n",
       "Index: []"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nulls\n",
    "df[df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create training and data set with normalized data\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df.d_won\n",
    "X = df.drop('d_won', axis=1)\n",
    "\n",
    "\n",
    "# Normalize the data from sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# x is for features, y is for targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#Funtion to retrieve K feature from SelectKBest\n",
    "def Features_from_SelectKBest(try_k):\n",
    "    # extract try_k best features\n",
    "    # score_func=f_classif,\n",
    "    skb = SelectKBest(k=try_k,  score_func=f_classif)\n",
    "    \n",
    "    # use those features to fit your model\n",
    "    fit = skb.fit(X_train, y_train)\n",
    "    \n",
    "    #Make training set with just those featurs\n",
    "    mask = fit.get_support()\n",
    "    k_set = X.columns[mask]\n",
    "    return k_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE #Recursive Feature Elimination\n",
    "\n",
    "def Backward_Model_Selection(model, amount_to_keep):\n",
    "    estimator = model()\n",
    "    selector = RFE(estimator, amount_to_keep, step=1) # keep five and remove variables one at a time (step) \n",
    "    selector = selector.fit(X_train, y_train)        # fit the model with the five kept features\n",
    "    mask = selector.support_            # show which are kept (True) and which are removed (False)\n",
    "    return X.columns[mask]            # show in what order they were removed highest removed first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE #Recursive Feature Elimination\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "selector = RFE(estimator, 5, step=1) # keep five and remove variables one at a time (step) \n",
    "selector = selector.fit(X, y)        # fit the model with the five kept features\n",
    "print(selector.support_)             # show which are kept (True) and which are removed (False)\n",
    "print(selector.ranking_)             # show in what order they were removed highest removed first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAH+CAYAAACBYPhbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ebcc2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward Stepwise Feature Selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=8, \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X, y)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "['year', 'state', 'population', 'total_vap', 'perc_vap', 'perc_reg', 'd_won', 'poverty', 'income', 'labor', 'unemployment']\n",
      "Selected Features: [ True False  True False False False False  True  True False False False\n",
      " False  True]\n",
      "Feature Ranking: [ 1  7  1  3  6  5  9  1  1 10  8  2  4  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction \n",
    "model = LogisticRegression() \n",
    "rfe = RFE(model,5).fit(X, y) # where 4 num of features to retain\n",
    "\n",
    "print(\"Num Features: %d\" % rfe.n_features_)\n",
    "print(list(df_pd))\n",
    "print(\"Selected Features: %s\" % rfe.support_) \n",
    "print(\"Feature Ranking: %s\" % rfe.ranking_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LASSO, Ridge and ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### values to help print values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_feature_coef(data):\n",
    "    # Create an empty data frame\n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    # Create a column of feature names\n",
    "    temp['features'] = names\n",
    "    temp['coef'] = data\n",
    "    \n",
    "    return temp.sort_values(by=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(how_many, data):\n",
    "    # Create an empty data frame\n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    # Create a column of feature names\n",
    "    temp['features'] = names\n",
    "    temp['coef'] = data\n",
    "    temp['coef'] = df['coef'].abs()\n",
    "    top = temp.nlargest(how_many, 'coef')\n",
    "    return top.features.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function called lasso,\n",
    "def compare_lasso(alphas):\n",
    "    '''\n",
    "    Takes in a list of alphas. Outputs a dataframe containing the coefficients of lasso regressions from each alpha.\n",
    "    '''\n",
    "    # Create an empty data frame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Create a column of feature names\n",
    "    df['Feature Name'] = names\n",
    "    \n",
    "    # For each alpha value in the list of alpha values,\n",
    "    for alpha in alphas:\n",
    "        # Create a lasso regression with that alpha value,\n",
    "        lasso = linear_model.Lasso(alpha=alpha)\n",
    "        \n",
    "        # Fit the lasso regression\n",
    "        lasso.fit(X_train, y_train)\n",
    "        \n",
    "        # Create a column name for that alpha value\n",
    "        column_name = 'Alpha = %f' % alpha\n",
    "\n",
    "        # Create a column of coefficient values\n",
    "        df[column_name] = lasso.coef_\n",
    "        \n",
    "    # Return the datafram    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Alpha = 0.010000</th>\n",
       "      <th>Alpha = 0.050000</th>\n",
       "      <th>Alpha = 0.100000</th>\n",
       "      <th>Alpha = 0.200000</th>\n",
       "      <th>Alpha = 0.500000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>-0.163195</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_vap</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>0.042158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perc_vap</td>\n",
       "      <td>0.047582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perc_reg</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poverty</td>\n",
       "      <td>-0.059989</td>\n",
       "      <td>-0.112250</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>income</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>0.070143</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>labor</td>\n",
       "      <td>0.032851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unemployment</td>\n",
       "      <td>0.124426</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_revenue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>property_expense</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_edu_expense</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>per_pupil_expense</td>\n",
       "      <td>0.126618</td>\n",
       "      <td>0.139684</td>\n",
       "      <td>0.121319</td>\n",
       "      <td>0.061081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature Name  Alpha = 0.010000  Alpha = 0.050000  Alpha = 0.100000  \\\n",
       "0                year         -0.163195         -0.004543         -0.000000   \n",
       "1               state          0.004526         -0.000000         -0.000000   \n",
       "2          population          0.000000          0.000000          0.000000   \n",
       "3           total_vap          0.024124          0.042158          0.000000   \n",
       "4            perc_vap          0.047582          0.000000          0.000000   \n",
       "5            perc_reg         -0.000000          0.000000          0.000000   \n",
       "6             poverty         -0.059989         -0.112250         -0.021145   \n",
       "7              income          0.223214          0.072925          0.070143   \n",
       "8               labor          0.032851          0.000000          0.000000   \n",
       "9        unemployment          0.124426          0.069106          0.000000   \n",
       "10      total_revenue          0.000000          0.000000          0.000000   \n",
       "11   property_expense          0.002494          0.000000          0.000000   \n",
       "12  total_edu_expense          0.000000          0.000000          0.001230   \n",
       "13  per_pupil_expense          0.126618          0.139684          0.121319   \n",
       "\n",
       "    Alpha = 0.200000  Alpha = 0.500000  \n",
       "0          -0.000000              -0.0  \n",
       "1          -0.000000               0.0  \n",
       "2           0.000000               0.0  \n",
       "3           0.000000               0.0  \n",
       "4           0.000000               0.0  \n",
       "5           0.000000               0.0  \n",
       "6          -0.000000              -0.0  \n",
       "7           0.004792               0.0  \n",
       "8           0.000000               0.0  \n",
       "9           0.000000               0.0  \n",
       "10          0.000000               0.0  \n",
       "11          0.000000               0.0  \n",
       "12          0.000000               0.0  \n",
       "13          0.061081               0.0  "
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the function called, Lasso\n",
    "compare_lasso([.01, .05, .1, .2, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elunsford/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>-1.974339e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>population</td>\n",
       "      <td>-1.878713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>property_expense</td>\n",
       "      <td>-9.449234e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_edu_expense</td>\n",
       "      <td>-1.750529e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perc_reg</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poverty</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_revenue</td>\n",
       "      <td>2.461139e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_vap</td>\n",
       "      <td>3.459747e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>labor</td>\n",
       "      <td>4.303092e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>income</td>\n",
       "      <td>1.936357e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>per_pupil_expense</td>\n",
       "      <td>5.565260e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>6.093359e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perc_vap</td>\n",
       "      <td>4.893715e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unemployment</td>\n",
       "      <td>1.956698e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             features          coef\n",
       "0                year -1.974339e-02\n",
       "2          population -1.878713e-07\n",
       "11   property_expense -9.449234e-11\n",
       "12  total_edu_expense -1.750529e-11\n",
       "5            perc_reg -0.000000e+00\n",
       "6             poverty  0.000000e+00\n",
       "10      total_revenue  2.461139e-12\n",
       "3           total_vap  3.459747e-08\n",
       "8               labor  4.303092e-07\n",
       "7              income  1.936357e-05\n",
       "13  per_pupil_expense  5.565260e-05\n",
       "1               state  6.093359e-05\n",
       "4            perc_vap  4.893715e-03\n",
       "9        unemployment  1.956698e-02"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LASSO\n",
    "from sklearn import linear_model\n",
    "\n",
    "alpha = .08 # Increasing alpha can shrink more variable coefficients to 0\n",
    "clf = linear_model.Lasso(alpha=alpha)\n",
    "lasso_fs = clf.fit(X, y)\n",
    "\n",
    "print_feature_coef(lasso_fs.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_features = get_top_values(8, lasso_fs.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function called lasso,\n",
    "def compare_ridge(alphas):\n",
    "    '''\n",
    "    Takes in a list of alphas. Outputs a dataframe containing the coefficients of lasso regressions from each alpha.\n",
    "    '''\n",
    "    # Create an empty data frame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Create a column of feature names\n",
    "    df['Feature Name'] = names\n",
    "    \n",
    "    # For each alpha value in the list of alpha values,\n",
    "    for alpha in alphas:\n",
    "        # Create a lasso regression with that alpha value,\n",
    "        ridge = linear_model.Ridge(alpha=alpha)\n",
    "        \n",
    "        # Fit the lasso regression\n",
    "        ridge.fit(X, y)\n",
    "        \n",
    "        # Create a column name for that alpha value\n",
    "        column_name = 'Alpha = %f' % alpha\n",
    "\n",
    "        # Create a column of coefficient values\n",
    "        df[column_name] = ridge.coef_\n",
    "        \n",
    "    # Return the datafram    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Alpha = 0.000100</th>\n",
       "      <th>Alpha = 0.800000</th>\n",
       "      <th>Alpha = 0.500000</th>\n",
       "      <th>Alpha = 10.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>-3.134728e-02</td>\n",
       "      <td>-3.134028e-02</td>\n",
       "      <td>-3.134292e-02</td>\n",
       "      <td>-3.125346e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>1.360557e-03</td>\n",
       "      <td>1.358815e-03</td>\n",
       "      <td>1.359468e-03</td>\n",
       "      <td>1.338885e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>population</td>\n",
       "      <td>-3.466187e-07</td>\n",
       "      <td>-3.467563e-07</td>\n",
       "      <td>-3.467047e-07</td>\n",
       "      <td>-3.482944e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_vap</td>\n",
       "      <td>1.046930e-08</td>\n",
       "      <td>1.044855e-08</td>\n",
       "      <td>1.045632e-08</td>\n",
       "      <td>1.021799e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perc_vap</td>\n",
       "      <td>7.769639e-03</td>\n",
       "      <td>7.768367e-03</td>\n",
       "      <td>7.768846e-03</td>\n",
       "      <td>7.752349e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perc_reg</td>\n",
       "      <td>-4.068511e-03</td>\n",
       "      <td>-4.065778e-03</td>\n",
       "      <td>-4.066802e-03</td>\n",
       "      <td>-4.034943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poverty</td>\n",
       "      <td>6.322664e-03</td>\n",
       "      <td>6.359190e-03</td>\n",
       "      <td>6.345534e-03</td>\n",
       "      <td>6.753723e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>income</td>\n",
       "      <td>2.433415e-05</td>\n",
       "      <td>2.433163e-05</td>\n",
       "      <td>2.433258e-05</td>\n",
       "      <td>2.429836e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>labor</td>\n",
       "      <td>7.606527e-07</td>\n",
       "      <td>7.609747e-07</td>\n",
       "      <td>7.608541e-07</td>\n",
       "      <td>7.645710e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unemployment</td>\n",
       "      <td>6.236200e-02</td>\n",
       "      <td>6.224298e-02</td>\n",
       "      <td>6.228755e-02</td>\n",
       "      <td>6.091483e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_revenue</td>\n",
       "      <td>-2.623893e-11</td>\n",
       "      <td>-2.624957e-11</td>\n",
       "      <td>-2.624558e-11</td>\n",
       "      <td>-2.637159e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>property_expense</td>\n",
       "      <td>-1.202339e-10</td>\n",
       "      <td>-1.202507e-10</td>\n",
       "      <td>-1.202444e-10</td>\n",
       "      <td>-1.204383e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_edu_expense</td>\n",
       "      <td>1.677232e-11</td>\n",
       "      <td>1.678168e-11</td>\n",
       "      <td>1.677817e-11</td>\n",
       "      <td>1.689017e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>per_pupil_expense</td>\n",
       "      <td>4.374616e-05</td>\n",
       "      <td>4.376413e-05</td>\n",
       "      <td>4.375740e-05</td>\n",
       "      <td>4.396737e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature Name  Alpha = 0.000100  Alpha = 0.800000  Alpha = 0.500000  \\\n",
       "0                year     -3.134728e-02     -3.134028e-02     -3.134292e-02   \n",
       "1               state      1.360557e-03      1.358815e-03      1.359468e-03   \n",
       "2          population     -3.466187e-07     -3.467563e-07     -3.467047e-07   \n",
       "3           total_vap      1.046930e-08      1.044855e-08      1.045632e-08   \n",
       "4            perc_vap      7.769639e-03      7.768367e-03      7.768846e-03   \n",
       "5            perc_reg     -4.068511e-03     -4.065778e-03     -4.066802e-03   \n",
       "6             poverty      6.322664e-03      6.359190e-03      6.345534e-03   \n",
       "7              income      2.433415e-05      2.433163e-05      2.433258e-05   \n",
       "8               labor      7.606527e-07      7.609747e-07      7.608541e-07   \n",
       "9        unemployment      6.236200e-02      6.224298e-02      6.228755e-02   \n",
       "10      total_revenue     -2.623893e-11     -2.624957e-11     -2.624558e-11   \n",
       "11   property_expense     -1.202339e-10     -1.202507e-10     -1.202444e-10   \n",
       "12  total_edu_expense      1.677232e-11      1.678168e-11      1.677817e-11   \n",
       "13  per_pupil_expense      4.374616e-05      4.376413e-05      4.375740e-05   \n",
       "\n",
       "    Alpha = 10.000000  \n",
       "0       -3.125346e-02  \n",
       "1        1.338885e-03  \n",
       "2       -3.482944e-07  \n",
       "3        1.021799e-08  \n",
       "4        7.752349e-03  \n",
       "5       -4.034943e-03  \n",
       "6        6.753723e-03  \n",
       "7        2.429836e-05  \n",
       "8        7.645710e-07  \n",
       "9        6.091483e-02  \n",
       "10      -2.637159e-11  \n",
       "11      -1.204383e-10  \n",
       "12       1.689017e-11  \n",
       "13       4.396737e-05  "
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the function called, Lasso\n",
    "alphas = [.0001, 0.8, .5, 10]\n",
    "compare_ridge(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.13429161e-02   1.35946813e-03  -3.46704723e-07   1.04563173e-08\n",
      "   7.76884643e-03  -4.06680165e-03   6.34553430e-03   2.43325846e-05\n",
      "   7.60854099e-07   6.22875505e-02  -2.62455820e-11  -1.20244403e-10\n",
      "   1.67781695e-11   4.37573986e-05]\n",
      "61.005184007\n",
      "Sum of square of coefficients = 0.00\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn import linear_model\n",
    "alpha = .5\n",
    "clf = linear_model.Ridge(alpha=alpha)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "\n",
    "# Increasing alpha can compress the L2 norm of the coefficients to 0 (but not selecting variables)\n",
    "print(\"Sum of square of coefficients = %.2f\"%np.sum(clf.coef_**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.49391873e-03  -0.00000000e+00  -2.79687164e-07   4.91399104e-08\n",
      "   0.00000000e+00   0.00000000e+00  -0.00000000e+00   1.35758074e-05\n",
      "   6.06928974e-07   0.00000000e+00  -5.05998707e-12  -9.82853578e-11\n",
      "  -1.19127932e-11   6.22964712e-05]\n",
      "8.00709585222\n",
      "Sum of square of coefficients = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elunsford/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "alpha = .5\n",
    "clf = linear_model.ElasticNet(alpha=alpha)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "\n",
    "print(\"Sum of square of coefficients = %.2f\"%np.sum(clf.coef_**2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Run_Decision_Tree_Model_with_feature_set(feature_set):\n",
    "    # make the model\n",
    "    dec_tree_ent = DecisionTreeClassifier(criterion='entropy', max_depth=4).fit(X_train.loc[:,feature_set],y_train)\n",
    "    \n",
    "    #run the model\n",
    "    y_predict = dec_tree_ent.predict(X_test.loc[:,feature_set])\n",
    "\n",
    "    #return the accuracy of the model\n",
    "    return (accuracy_score(y_test, y_predict) * 100)\n",
    "\n",
    "def Run_RandomForest_with_feature_set(feature_set):\n",
    "    nTrees = 100\n",
    "    max_depth = 5\n",
    "    min_node_size = 5\n",
    "    verbose = 0\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=nTrees, max_depth=max_depth, random_state=0, verbose=verbose, min_samples_leaf=min_node_size)\n",
    "    clf.fit(X_train.loc[:, feature_set], y_train)\n",
    "    \n",
    "    #Predict\n",
    "    y_predict = clf.predict(X_test.loc[:, feature_set])\n",
    "    \n",
    "    #return the accuracy of the model\n",
    "    return (accuracy_score(y_test, y_predict) * 100)\n",
    "\n",
    "def Run_GradientBoostingClassifer_with_feature_set(feature_set):\n",
    "    nTrees = 100\n",
    "    max_depth = 5\n",
    "    min_node_size = 5\n",
    "    verbose = 0\n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    gbm_clf = GradientBoostingClassifier(n_estimators=nTrees, loss='deviance', learning_rate=learning_rate, max_depth=max_depth, \\\n",
    "                                    min_samples_leaf=min_node_size)\n",
    "    gbm_clf.fit(X_train.loc[:, feature_set], y_train)\n",
    "\n",
    "    y_predict = gbm_clf.predict(X_test.loc[:, feature_set])\n",
    "    \n",
    "    #return the accuracy of the model\n",
    "    return (accuracy_score(y_test, y_predict) * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DecisionTree_with_SelectKBest(try_k):\n",
    "    # Get K Features with SelectKBest\n",
    "    feature_set = Features_from_SelectKBest(try_k)\n",
    "    results = Run_Decision_Tree_Model_with_feature_set(feature_set)\n",
    "    \n",
    "    return [results, 'decision_tree', 'selectKBest', feature_set.values]\n",
    "    \n",
    "def DecisionTree_with_Backward_Model(try_k):\n",
    "    feature_set = Backward_Model_Selection(DecisionTreeClassifier, x)\n",
    "    results = Run_Decision_Tree_Model_with_feature_set(feature_set)\n",
    "    \n",
    "    return [results, 'decision_tree', 'Backward_Model', feature_set.values]\n",
    "    \n",
    "# Make function to run RandomForest\n",
    "def RandomForest_with_SelectKBest(try_k):\n",
    "    k_set = Features_from_SelectKBest(try_k)\n",
    "    results = Run_RandomForest_with_feature_set(k_set)\n",
    "    \n",
    "    return [results, 'RandomForest', 'SelectKBest', k_set.values]\n",
    "\n",
    "# Make Function to Run Random Forest\n",
    "def GradientBoostingClassifier_with_SelectKBest(try_k): \n",
    "    feature_set = Features_from_SelectKBest(try_k)\n",
    "    results = Run_GradientBoostingClassifer_with_feature_set(feature_set)\n",
    "    \n",
    "    return [results, 'GrandientBoostingClassier', 'SelectKBest', feature_set.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fs</th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>2</td>\n",
       "      <td>85.964912</td>\n",
       "      <td>[[income, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>14</td>\n",
       "      <td>80.701754</td>\n",
       "      <td>[[year, state, population, total_vap, perc_vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>11</td>\n",
       "      <td>80.701754</td>\n",
       "      <td>[[population, total_vap, perc_vap, perc_reg, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>13</td>\n",
       "      <td>80.701754</td>\n",
       "      <td>[[year, population, total_vap, perc_vap, perc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>4</td>\n",
       "      <td>80.701754</td>\n",
       "      <td>[[perc_reg, poverty, labor, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>14</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, state, population, total_vap, perc_vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>9</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, population, total_vap, perc_reg, pover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>10</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, population, total_vap, perc_reg, pover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>11</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, population, total_vap, perc_reg, pover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>12</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, total_vap, perc_vap, perc_reg, poverty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>13</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, state, population, total_vap, perc_vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>3</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[poverty, income, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>2</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[income, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>13</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, population, total_vap, perc_vap, perc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>4</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[poverty, income, total_revenue, per_pupil_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>1</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>7</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[total_vap, poverty, income, labor, total_rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>14</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, state, population, total_vap, perc_vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>8</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[total_vap, perc_reg, poverty, income, labor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>7</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[total_vap, perc_reg, poverty, income, unempl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>6</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[total_vap, perc_reg, poverty, income, unempl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>13</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, population, total_vap, perc_vap, perc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>3</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[poverty, income, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>9</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[population, total_vap, poverty, income, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>11</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[population, total_vap, perc_vap, perc_reg, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>12</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[population, total_vap, perc_vap, perc_reg, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>10</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[population, total_vap, perc_reg, poverty, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>14</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[year, state, population, total_vap, perc_vap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>3</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[total_vap, perc_reg, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>12</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>[[population, total_vap, perc_vap, perc_reg, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>6</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[total_vap, poverty, income, total_revenue, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>2</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[income, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>5</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[total_vap, perc_reg, poverty, unemployment, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>8</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[population, total_vap, poverty, income, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>4</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[poverty, income, total_revenue, per_pupil_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>8</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[population, total_vap, poverty, income, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>12</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[population, total_vap, perc_vap, perc_reg, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>10</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>[[population, total_vap, perc_reg, poverty, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>7</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[total_vap, poverty, income, labor, total_rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>10</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[population, total_vap, perc_reg, poverty, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>1</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>9</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[population, total_vap, poverty, income, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>6</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[total_vap, poverty, income, total_revenue, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>5</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[poverty, income, total_revenue, total_edu_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>3</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[poverty, income, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>1</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>9</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[population, total_vap, poverty, income, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>7</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[total_vap, poverty, income, labor, total_rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>6</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[total_vap, poverty, income, total_revenue, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>5</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[poverty, income, total_revenue, total_edu_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>4</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[poverty, income, total_revenue, per_pupil_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>1</td>\n",
       "      <td>75.438596</td>\n",
       "      <td>[[per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Backward_Model</td>\n",
       "      <td>2</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>[[total_vap, per_pupil_expense]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>5</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>[[poverty, income, total_revenue, total_edu_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>selectKBest</td>\n",
       "      <td>8</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>[[population, total_vap, poverty, income, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrandientBoostingClassier</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>11</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>[[population, total_vap, perc_vap, perc_reg, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model              fs   k   accuracy  \\\n",
       "0  GrandientBoostingClassier     SelectKBest   2  85.964912   \n",
       "0  GrandientBoostingClassier     SelectKBest  14  80.701754   \n",
       "0               RandomForest     SelectKBest  11  80.701754   \n",
       "0  GrandientBoostingClassier     SelectKBest  13  80.701754   \n",
       "0              decision_tree  Backward_Model   4  80.701754   \n",
       "0              decision_tree  Backward_Model  14  78.947368   \n",
       "0              decision_tree  Backward_Model   9  78.947368   \n",
       "0              decision_tree  Backward_Model  10  78.947368   \n",
       "0              decision_tree  Backward_Model  11  78.947368   \n",
       "0              decision_tree  Backward_Model  12  78.947368   \n",
       "0              decision_tree  Backward_Model  13  78.947368   \n",
       "0  GrandientBoostingClassier     SelectKBest   3  78.947368   \n",
       "0              decision_tree     selectKBest   2  78.947368   \n",
       "0               RandomForest     SelectKBest  13  78.947368   \n",
       "0               RandomForest     SelectKBest   4  78.947368   \n",
       "0  GrandientBoostingClassier     SelectKBest   1  78.947368   \n",
       "0               RandomForest     SelectKBest   7  78.947368   \n",
       "0               RandomForest     SelectKBest  14  78.947368   \n",
       "0              decision_tree  Backward_Model   8  78.947368   \n",
       "0              decision_tree  Backward_Model   7  78.947368   \n",
       "0              decision_tree  Backward_Model   6  78.947368   \n",
       "0              decision_tree     selectKBest  13  78.947368   \n",
       "0              decision_tree     selectKBest   3  78.947368   \n",
       "0  GrandientBoostingClassier     SelectKBest   9  78.947368   \n",
       "0              decision_tree     selectKBest  11  78.947368   \n",
       "0              decision_tree     selectKBest  12  78.947368   \n",
       "0              decision_tree     selectKBest  10  78.947368   \n",
       "0              decision_tree     selectKBest  14  78.947368   \n",
       "0              decision_tree  Backward_Model   3  78.947368   \n",
       "0               RandomForest     SelectKBest  12  78.947368   \n",
       "0  GrandientBoostingClassier     SelectKBest   6  77.192982   \n",
       "0               RandomForest     SelectKBest   2  77.192982   \n",
       "0              decision_tree  Backward_Model   5  77.192982   \n",
       "0  GrandientBoostingClassier     SelectKBest   8  77.192982   \n",
       "0  GrandientBoostingClassier     SelectKBest   4  77.192982   \n",
       "0               RandomForest     SelectKBest   8  77.192982   \n",
       "0  GrandientBoostingClassier     SelectKBest  12  77.192982   \n",
       "0               RandomForest     SelectKBest  10  77.192982   \n",
       "0  GrandientBoostingClassier     SelectKBest   7  75.438596   \n",
       "0  GrandientBoostingClassier     SelectKBest  10  75.438596   \n",
       "0              decision_tree     selectKBest   1  75.438596   \n",
       "0               RandomForest     SelectKBest   9  75.438596   \n",
       "0               RandomForest     SelectKBest   6  75.438596   \n",
       "0               RandomForest     SelectKBest   5  75.438596   \n",
       "0               RandomForest     SelectKBest   3  75.438596   \n",
       "0              decision_tree  Backward_Model   1  75.438596   \n",
       "0              decision_tree     selectKBest   9  75.438596   \n",
       "0              decision_tree     selectKBest   7  75.438596   \n",
       "0              decision_tree     selectKBest   6  75.438596   \n",
       "0              decision_tree     selectKBest   5  75.438596   \n",
       "0              decision_tree     selectKBest   4  75.438596   \n",
       "0               RandomForest     SelectKBest   1  75.438596   \n",
       "0              decision_tree  Backward_Model   2  73.684211   \n",
       "0  GrandientBoostingClassier     SelectKBest   5  73.684211   \n",
       "0              decision_tree     selectKBest   8  73.684211   \n",
       "0  GrandientBoostingClassier     SelectKBest  11  73.684211   \n",
       "\n",
       "                                            features  \n",
       "0                      [[income, per_pupil_expense]]  \n",
       "0  [[year, state, population, total_vap, perc_vap...  \n",
       "0  [[population, total_vap, perc_vap, perc_reg, p...  \n",
       "0  [[year, population, total_vap, perc_vap, perc_...  \n",
       "0    [[perc_reg, poverty, labor, per_pupil_expense]]  \n",
       "0  [[year, state, population, total_vap, perc_vap...  \n",
       "0  [[year, population, total_vap, perc_reg, pover...  \n",
       "0  [[year, population, total_vap, perc_reg, pover...  \n",
       "0  [[year, population, total_vap, perc_reg, pover...  \n",
       "0  [[year, total_vap, perc_vap, perc_reg, poverty...  \n",
       "0  [[year, state, population, total_vap, perc_vap...  \n",
       "0             [[poverty, income, per_pupil_expense]]  \n",
       "0                      [[income, per_pupil_expense]]  \n",
       "0  [[year, population, total_vap, perc_vap, perc_...  \n",
       "0  [[poverty, income, total_revenue, per_pupil_ex...  \n",
       "0                              [[per_pupil_expense]]  \n",
       "0  [[total_vap, poverty, income, labor, total_rev...  \n",
       "0  [[year, state, population, total_vap, perc_vap...  \n",
       "0  [[total_vap, perc_reg, poverty, income, labor,...  \n",
       "0  [[total_vap, perc_reg, poverty, income, unempl...  \n",
       "0  [[total_vap, perc_reg, poverty, income, unempl...  \n",
       "0  [[year, population, total_vap, perc_vap, perc_...  \n",
       "0             [[poverty, income, per_pupil_expense]]  \n",
       "0  [[population, total_vap, poverty, income, labo...  \n",
       "0  [[population, total_vap, perc_vap, perc_reg, p...  \n",
       "0  [[population, total_vap, perc_vap, perc_reg, p...  \n",
       "0  [[population, total_vap, perc_reg, poverty, in...  \n",
       "0  [[year, state, population, total_vap, perc_vap...  \n",
       "0         [[total_vap, perc_reg, per_pupil_expense]]  \n",
       "0  [[population, total_vap, perc_vap, perc_reg, p...  \n",
       "0  [[total_vap, poverty, income, total_revenue, t...  \n",
       "0                      [[income, per_pupil_expense]]  \n",
       "0  [[total_vap, perc_reg, poverty, unemployment, ...  \n",
       "0  [[population, total_vap, poverty, income, labo...  \n",
       "0  [[poverty, income, total_revenue, per_pupil_ex...  \n",
       "0  [[population, total_vap, poverty, income, labo...  \n",
       "0  [[population, total_vap, perc_vap, perc_reg, p...  \n",
       "0  [[population, total_vap, perc_reg, poverty, in...  \n",
       "0  [[total_vap, poverty, income, labor, total_rev...  \n",
       "0  [[population, total_vap, perc_reg, poverty, in...  \n",
       "0                              [[per_pupil_expense]]  \n",
       "0  [[population, total_vap, poverty, income, labo...  \n",
       "0  [[total_vap, poverty, income, total_revenue, t...  \n",
       "0  [[poverty, income, total_revenue, total_edu_ex...  \n",
       "0             [[poverty, income, per_pupil_expense]]  \n",
       "0                              [[per_pupil_expense]]  \n",
       "0  [[population, total_vap, poverty, income, labo...  \n",
       "0  [[total_vap, poverty, income, labor, total_rev...  \n",
       "0  [[total_vap, poverty, income, total_revenue, t...  \n",
       "0  [[poverty, income, total_revenue, total_edu_ex...  \n",
       "0  [[poverty, income, total_revenue, per_pupil_ex...  \n",
       "0                              [[per_pupil_expense]]  \n",
       "0                   [[total_vap, per_pupil_expense]]  \n",
       "0  [[poverty, income, total_revenue, total_edu_ex...  \n",
       "0  [[population, total_vap, poverty, income, labo...  \n",
       "0  [[population, total_vap, perc_vap, perc_reg, p...  "
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.DataFrame(columns=['model','fs','k','accuracy','features'])\n",
    "\n",
    "models = [DecisionTree_with_SelectKBest,\n",
    "          DecisionTree_with_Backward_Model,\n",
    "          RandomForest_with_SelectKBest,\n",
    "          GradientBoostingClassifier_with_SelectKBest]\n",
    "\n",
    "for m in models:\n",
    "    for x in range(1 , X_train.shape[1]+1):\n",
    "        results = m(x) \n",
    "        row = pd.DataFrame({'model':[results[1]],\n",
    "                        'fs':[results[2]],\n",
    "                        'k':[x],\n",
    "                        'accuracy' :[results[0]],\n",
    "                        'features': [[results[3]]]})\n",
    "        all_results = all_results.append(row)\n",
    "\n",
    "all_results.sort_values(by = 'accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Machine Learning Model(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
